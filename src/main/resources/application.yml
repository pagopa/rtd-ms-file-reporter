spring.application.name: rtdfilereporter
logging:
  level:
    root: INFO
    org.apache.kafka: WARN
    com.azure.monitor.opentelemetry.exporter.implementation.builders.TelemetryTruncation: ERROR

# OpenTelemetry
applicationinsights.enabled: '@applicationinsights.enabled@'
otel.log.level: ${OPENTELEMETRY_LOG_LEVEL:INFO}
otel.instrumentation.logback-appender.enabled: true # enable logback instrumentation
otel.traces.sampler.probability: 1.0 # sample probability for tracing (spans)
otel.metric.export.interval: 60000 # sampling rate for metrics (millis)
otel.exporter.otlp.enabled: false # disable send to OTLP endpoint

topics:
  rtd-projector:
    topic: ${KAFKA_RTD_PROJECTOR_TOPIC:rtd-projector}
    group: ${KAFKA_RTD_PROJECTOR_CONSUMER_GROUP:rtd-file-reporter-consumer-group}

report:
  fileTTL: ${FILE_TTL_IN_DAYS:15}

spring:
  config:
    activate:
      on-profile: default
  data:
    mongodb:
      uri: ${MONGODB_CONNECTION_URI:mongodb://localhost:27017}
      database: ${MONGODB_NAME:rtd}
  cloud:
    openfeign:
      client:
        config:
          StorageAccountConnector:
            url: https://${STORAGE_ACCOUNT_HOST:internal.it}/storage
            apiKey: ${INTERNAL_SERVICES_API_KEY:myApiKey}
    stream:
      bindings:
        projectorConsumer-in-0: # name must match [handler name]-in-0
          destination: ${topics.rtd-projector.topic}
          group: ${topics.rtd-projector.group}
          content-type: application/json
          binder: projector
          consumer:
            max-attempts: 1

      kafka:
        binder:
          configuration:
            security.protocol: SASL_SSL
            sasl.mechanism: PLAIN

      binders:
        projector:
          type: kafka
          environment.spring.cloud.stream.kafka:
            binder:
              auto-create-topics: false
              brokers: ${KAFKA_RTD_PROJECTOR_BROKER:localhost:29095}
              configuration:
                sasl.jaas.config: ${KAFKA_RTD_PROJECTOR_SASL_JAAS_CONFIG}
              consumerProperties:
                key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
                value.deserializer: org.apache.kafka.common.serialization.StringDeserializer

# Enable only health probes
management:
  metrics:
    export.defaults.enabled: false
    enable:
      all: false
      process.cpu: true
      system.cpu: true
      jvm.memory: true
      application: true
  info.defaults.enabled: false
  endpoints:
    enabled-by-default: false
    web.exposure.include: health
  endpoint:
    health:
      enabled: true
      probes:
        enabled: true

---
topics:
  rtd-projector:
    topic: ${KAFKA_RTD_PROJECTOR_TOPIC:rtd-projector}
    group: ${KAFKA_RTD_PROJECTOR_CONSUMER_GROUP:rtd-file-reporter-consumer-group}

report:
  fileTTL: ${FILE_TTL_IN_DAYS:15}

spring:
  config:
    activate:
      on-profile: dev
  data:
    mongodb:
      uri: ${MONGODB_CONNECTION_URI:mongodb://localhost:27017}
      database: ${MONGODB_NAME:fileregister}
  cloud:
    stream:
      bindings:
        projectorConsumer-in-0: # name must match [handler name]-in-0
          destination: ${topics.rtd-projector.topic}
          group: ${topics.rtd-projector.group}
          content-type: application/json
          binder: projector
          consumer:
            max-attempts: 1
      binders:
        projector:
          type: kafka
          environment.spring.cloud.stream.kafka:
            binder:
              auto-create-topics: true
              brokers: ${KAFKA_RTD_PROJECTOR_BROKER:localhost:29095}
              consumerProperties:
                key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
                value.deserializer: org.apache.kafka.common.serialization.StringDeserializer
