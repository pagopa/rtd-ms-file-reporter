spring.application.name: rtdfilereporter
logging:
  level:
    root: INFO
    org.apache.kafka: WARN
    com.azure.monitor.opentelemetry.exporter.implementation.builders.TelemetryTruncation: ERROR

# OpenTelemetry
applicationinsights:
  enabled: '@applicationinsights.enabled@'
  connection-string: ${APPLICATIONINSIGHTS_CONNECTION_STRING:myconnectionstring}
otel:
  log:
    level: ${OPENTELEMETRY_LOG_LEVEL:INFO}
  traces:
    sampler:
      probability: 1.0 # sample probability for tracing (spans)
  metric:
    export:
      interval: 60000 # sampling rate for metrics (millis)
  instrumentation:
    logback-appender:
      enabled: true # enable logback instrumentation
    micrometer:
      enabled: false

topics:
  rtd-projector:
    topic: ${KAFKA_RTD_PROJECTOR_TOPIC:rtd-projector}
    group: ${KAFKA_RTD_PROJECTOR_CONSUMER_GROUP:rtd-file-reporter-consumer-group}

report:
  fileTTL: ${FILE_TTL_IN_DAYS:15}

storage-account-connector:
  url: https://${STORAGE_ACCOUNT_HOST:httpbin.org}/storage
  apiKey: ${INTERNAL_SERVICES_API_KEY:myApiKey}

spring:
  config:
    activate:
      on-profile: default
  data:
    mongodb:
      uri: ${MONGODB_CONNECTION_URI:mongodb://localhost:27017}
      database: ${MONGODB_NAME:rtd}
  cloud:
    function:
      definition: projectorConsumer
    stream:
      bindings:
        projectorConsumer-in-0: # name must match [handler name]-in-0
          destination: ${topics.rtd-projector.topic}
          group: ${topics.rtd-projector.group}
          content-type: application/json
          binder: projector
          consumer:
            max-attempts: 1

      kafka:
        binder:
          configuration:
            security.protocol: SASL_SSL
            sasl.mechanism: PLAIN

      binders:
        projector:
          type: kafka
          environment.spring.cloud.stream.kafka:
            binder:
              auto-create-topics: false
              brokers: ${KAFKA_RTD_PROJECTOR_BROKER:localhost:29095}
              configuration:
                sasl.jaas.config: ${KAFKA_RTD_PROJECTOR_SASL_JAAS_CONFIG}
              consumerProperties:
                key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
                value.deserializer: org.apache.kafka.common.serialization.StringDeserializer

# Enable only health probes
management:
  metrics:
    export.defaults.enabled: false
    enable:
      all: false
      process.cpu: false
      system.cpu: false
      jvm.memory: false
      application: false
  info.defaults.enabled: false
  endpoints:
    enabled-by-default: false
    web.exposure.include: health
  endpoint:
    health:
      enabled: true
      probes:
        enabled: true

---
topics:
  rtd-projector:
    topic: ${KAFKA_RTD_PROJECTOR_TOPIC:rtd-projector}
    group: ${KAFKA_RTD_PROJECTOR_CONSUMER_GROUP:rtd-file-reporter-consumer-group}

report:
  fileTTL: ${FILE_TTL_IN_DAYS:15}

spring:
  config:
    activate:
      on-profile: dev
  data:
    mongodb:
      uri: ${MONGODB_CONNECTION_URI:mongodb://localhost:27017}
      database: ${MONGODB_NAME:fileregister}
  cloud:
    stream:
      bindings:
        projectorConsumer-in-0: # name must match [handler name]-in-0
          destination: ${topics.rtd-projector.topic}
          group: ${topics.rtd-projector.group}
          content-type: application/json
          binder: projector
          consumer:
            max-attempts: 1
      binders:
        projector:
          type: kafka
          environment.spring.cloud.stream.kafka:
            binder:
              auto-create-topics: true
              brokers: ${KAFKA_RTD_PROJECTOR_BROKER:localhost:29095}
              consumerProperties:
                key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
                value.deserializer: org.apache.kafka.common.serialization.StringDeserializer
